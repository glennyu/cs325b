{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import datetime\n",
    "import nltk\n",
    "from nltk.tokenize import casual_tokenize\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_PATH = '../data/'\n",
    "TWEET_PATH = '/mnt/mounted_bucket/'\n",
    "week_words = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings shape: (1193514, 50)\n",
      "Number of keywords: 286\n"
     ]
    }
   ],
   "source": [
    "embedding_keywords = set()\n",
    "word_dict = {}\n",
    "word_list = []\n",
    "word_embeddings = []\n",
    "with open(EMBEDDINGS_PATH + \"glove.twitter.27B.50d.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        word = line.split()[0]\n",
    "        if word.isalpha():\n",
    "            for day in week_words:\n",
    "                if day in word:\n",
    "                    embedding_keywords.add(len(word_embeddings))\n",
    "                    break\n",
    "        word_dict[word] = len(word_embeddings)\n",
    "        word_list.append(word)\n",
    "        word_embeddings.append([float(x) for x in line.split()[1:]])\n",
    "        while (len(word_embeddings[-1]) < 50):\n",
    "            word_embeddings[-1].append(0.0)\n",
    "        word_embeddings[-1] = word_embeddings[-1][:50]\n",
    "word_embeddings = np.array(word_embeddings)\n",
    "print(\"Word embeddings shape:\", word_embeddings.shape)\n",
    "print(\"Number of keywords:\", len(embedding_keywords))\n",
    "keyword_to_feat_index = {}\n",
    "for i, idx in enumerate(embedding_keywords):\n",
    "    keyword_to_feat_index[idx] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(d):\n",
    "    year = int(d[:4])\n",
    "    month = int(d[5:7])\n",
    "    day = int(d[8:10])\n",
    "    return datetime.date(year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(tweet_file):\n",
    "    date_to_tweets = defaultdict(list)\n",
    "    with open(TWEET_PATH + tweet_file) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        missing_words = set()\n",
    "        cnt = 0\n",
    "        for row in reader:\n",
    "            date = get_date(row['postedTime'])\n",
    "            tweet = ' '.join([word for word in casual_tokenize(row['tweet']) if '@' not in word and 'http' not in word])\n",
    "            tweet = tweet.replace('#', '').lower()\n",
    "            tweet_embedding = []\n",
    "            for word in tweet.split():\n",
    "                if word in word_dict:\n",
    "                    tweet_embedding.append(word_dict[word])\n",
    "                else:\n",
    "                    tweet_embedding.append(-1)\n",
    "                    missing_words.add(word)\n",
    "            date_to_tweets[date].append(tweet_embedding)\n",
    "            cnt += 1\n",
    "            if (cnt % 200000 == 0): \n",
    "                print(str(cnt),'tweets processed...')\n",
    "        print(\"Number of missing words:\", len(missing_words))\n",
    "    return date_to_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(date_to_tweets):\n",
    "    features, labels = [], []\n",
    "    for date in date_to_tweets:\n",
    "        hist = defaultdict(int)\n",
    "        for tweet in date_to_tweets[date]:\n",
    "            for idx in tweet:\n",
    "                if idx in embedding_keywords:\n",
    "                    hist[idx] += 1\n",
    "        feat = np.zeros(len(embedding_keywords), dtype=np.float32)\n",
    "        for idx, cnt in hist.items():\n",
    "            feat[keyword_to_feat_index[idx]] = cnt\n",
    "        features.append(feat/len(date_to_tweets[date]))\n",
    "        labels.append(date.weekday())\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_features(features, labels):\n",
    "    conf_matrix = np.zeros((7, 7), dtype=np.int32)\n",
    "    day_dict = {}\n",
    "    for i, word in enumerate(week_words):\n",
    "        day_dict[word] = i\n",
    "        day_dict[word + 's'] = i\n",
    "    for i in range(features.shape[0]):\n",
    "        max_idx = np.argmax(features[i])\n",
    "        for key, val in keyword_to_feat_index.items():\n",
    "            if val == max_idx:\n",
    "                if word_list[key] not in day_dict:\n",
    "                    print(\"true:\", week_words[labels[i]], \"max:\", word_list[key], \"count:\", features[i][val])\n",
    "                else:\n",
    "                    conf_matrix[labels[i]][day_dict[word_list[key]]] += 1\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 tweets processed...\n",
      "400000 tweets processed...\n",
      "600000 tweets processed...\n",
      "800000 tweets processed...\n",
      "1000000 tweets processed...\n",
      "1200000 tweets processed...\n",
      "1400000 tweets processed...\n",
      "1600000 tweets processed...\n",
      "1800000 tweets processed...\n",
      "2000000 tweets processed...\n",
      "2200000 tweets processed...\n",
      "2400000 tweets processed...\n",
      "2600000 tweets processed...\n",
      "2800000 tweets processed...\n",
      "3000000 tweets processed...\n",
      "3200000 tweets processed...\n",
      "3400000 tweets processed...\n",
      "3600000 tweets processed...\n",
      "3800000 tweets processed...\n",
      "4000000 tweets processed...\n",
      "4200000 tweets processed...\n",
      "4400000 tweets processed...\n",
      "4600000 tweets processed...\n",
      "4800000 tweets processed...\n",
      "5000000 tweets processed...\n",
      "5200000 tweets processed...\n",
      "5400000 tweets processed...\n",
      "5600000 tweets processed...\n",
      "5800000 tweets processed...\n",
      "6000000 tweets processed...\n",
      "6200000 tweets processed...\n",
      "Number of missing words: 1044520\n"
     ]
    }
   ],
   "source": [
    "date_to_tweets = get_tweets('Delhi_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (1045, 286)\n",
      "Labels shape: (1045,)\n"
     ]
    }
   ],
   "source": [
    "features, labels = get_features_and_labels(date_to_tweets)\n",
    "print('Features shape:', features.shape)\n",
    "print('Labels shape:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: monday max: mondaymotivation count: 0.0028404845\n",
      "true: monday max: mondaymotivation count: 0.0034078518\n",
      "true: monday max: mondaymotivation count: 0.004001715\n",
      "true: saturday max: sexysaturday count: 0.0052533993\n",
      "true: friday max: fridayfeeling count: 0.010262562\n",
      "true: wednesday max: winewednesday count: 0.0021008404\n",
      "true: thursday max: throwbackthursday count: 0.0013708019\n",
      "true: saturday max: supersaturday count: 0.0031308704\n",
      "true: thursday max: throwbackthursday count: 0.00080153893\n",
      "true: monday max: mondaymotivation count: 0.0041007614\n",
      "true: thursday max: throwbackthursday count: 0.00062578224\n",
      "true: monday max: mondaymotivation count: 0.0027737226\n",
      "true: monday max: mondaymotivation count: 0.0043649063\n",
      "true: thursday max: goodfriday count: 0.0005947071\n",
      "true: wednesday max: winewednesday count: 0.0016709259\n",
      "true: monday max: mondaymotivation count: 0.0053823018\n",
      "true: tuesday max: transformationtuesday count: 0.00063582894\n",
      "true: monday max: mondaymotivation count: 0.0039770217\n",
      "true: thursday max: throwbackthursday count: 0.0009891196\n",
      "true: monday max: mondaymotivation count: 0.0030637255\n",
      "true: wednesday max: winewednesday count: 0.002117061\n",
      "true: monday max: mondaymotivation count: 0.004602444\n",
      "true: monday max: mondaymotivation count: 0.0023167075\n",
      "true: monday max: mondaymotivation count: 0.0024987506\n",
      "true: saturday max: fridayfeeling count: 0.007803298\n",
      "true: tuesday max: blackfriday count: 0.014717518\n",
      "true: friday max: itsfriday count: 0.0020266357\n",
      "true: saturday max: supersaturday count: 0.0036226835\n",
      "true: monday max: mondaymotivation count: 0.003532434\n",
      "true: wednesday max: traveltuesday count: 0.003224073\n",
      "true: monday max: mondaymotivation count: 0.0038308532\n",
      "true: thursday max: thirstythursday count: 0.00469894\n",
      "true: monday max: mondaymotivation count: 0.0041918955\n",
      "true: thursday max: throwbackthursday count: 0.0030198446\n",
      "true: saturday max: sexysaturday count: 0.0028696826\n",
      "[[113   1   1   0   1  16   1]\n",
      " [  3  83   4   3  12  21  21]\n",
      " [  3   2  68   3  17  32  22]\n",
      " [  3   0   1  63  24  23  30]\n",
      " [  1   0   1   0 118  21   7]\n",
      " [  5   1   0   0   2 124  11]\n",
      " [  0   1   0   0   2  13 132]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = analyze_features(features, labels)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
