{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Train the model\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from model.utils import Params\n",
    "from model.utils import set_logger\n",
    "from model.training import train_and_evaluate\n",
    "from model.input_fn import input_fn\n",
    "from model.input_fn import load_tweets_and_prices, load_word_embeddings\n",
    "from model.model_fn import model_fn\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_dir', default='experiments/base_model',\n",
    "                    help=\"Directory containing params.json\")\n",
    "parser.add_argument('--data_dir', default='data/', help=\"Directory containing the dataset\")\n",
    "parser.add_argument('--restore_dir', default=None,\n",
    "                    help=\"Optional, directory containing weights to reload before training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the random seed for the whole graph for reproductible experiments\n",
    "tf.set_random_seed(325)\n",
    "\n",
    "# Load the parameters from the experiment params.json file in model_dir\n",
    "args = parser.parse_args()\n",
    "json_path = os.path.join(args.model_dir, 'params.json')\n",
    "assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
    "params = Params(json_path)\n",
    "\n",
    "# Check that we are not overwriting some previous experiment\n",
    "# Comment these lines if you are developing your model and don't care about overwritting\n",
    "model_dir_has_best_weights = os.path.isdir(os.path.join(args.model_dir, \"best_weights\"))\n",
    "overwritting = model_dir_has_best_weights and args.restore_dir is None\n",
    "# assert not overwritting, \"Weights found in model_dir, aborting to avoid overwrite\"\n",
    "\n",
    "# Set the logger\n",
    "set_logger(os.path.join(args.model_dir, 'train.log'))\n",
    "\n",
    "# Get paths for dataset\n",
    "path_train_embeddings = os.path.join(args.data_dir, 'embeddings/')\n",
    "path_train_batches = os.path.join(args.data_dir, 'batches_train/')\n",
    "path_train_prices = os.path.join(args.data_dir, 'price_deviations.txt')\n",
    "path_eval_embeddings = os.path.join(args.data_dir, 'embeddings/')\n",
    "path_eval_batches = os.path.join(args.data_dir, 'batches_val/')\n",
    "path_eval_prices = os.path.join(args.data_dir, 'price_deviations.txt')\n",
    "path_word_embeddings = os.path.join(args.data_dir, 'glove.twitter.27B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the input data pipeline\n",
    "logging.info(\"Creating the datasets...\")\n",
    "train_tweets, train_prices = load_tweets_and_prices(path_train_embeddings, path_train_batches, path_train_prices)\n",
    "eval_tweets, eval_prices = load_tweets_and_prices(path_eval_embeddings, path_eval_batches, path_eval_prices)\n",
    "\n",
    "# Create the two iterators over the two datasets\n",
    "train_inputs = input_fn('train', train_tweets, train_prices, params)\n",
    "eval_inputs = input_fn('eval', eval_tweets, eval_prices, params)\n",
    "logging.info(\"- done.\")\n",
    "\n",
    "# Load word embeddings\n",
    "logging.info(\"Loading word embeddings...\")\n",
    "word_embeddings = load_word_embeddings(path_word_embeddings, params)\n",
    "logging.info(\"- done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the models (2 different set of nodes that share weights for train and eval)\n",
    "logging.info(\"Creating the model...\")\n",
    "train_model_spec = model_fn('train', word_embeddings, train_inputs, params)\n",
    "eval_model_spec = model_fn('eval', word_embeddings, eval_inputs, params, reuse=True)\n",
    "logging.info(\"- done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "logging.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n",
    "train_and_evaluate(train_model_spec, eval_model_spec, args.model_dir, params, args.restore_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
